{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"color:#FF8C00;text-align: center;vertical-align: middle;font-size:46px;\">Support Vector Machines</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The objective of the support vector machine algorithm is to find a hyperplane in an N-dimensional space(N ‚Äî the number of features) that distinctly classifies the data points.\n",
    "\n",
    "## What is Support Vector Machines (SVMs)?\n",
    "\n",
    "Suppose the training dataset contains two categories of data. So an an SVM algorithm builds a model that assigns new test datapoint to one category or the other, making it a non-probabilistic binary linear classifier.\n",
    "\n",
    "An SVM classifier builds a model that assigns new data points to one of the given categories. Thus, it can be viewed as a non-probabilistic binary linear classifier.\n",
    "\n",
    "The objective of applying SVMs is to find the best line (in two dimensions) or the best hyperplane (in more than two dimensions) in order to help us separate our space into classes. The hyperplane (line) is found through the maximum margin. i.e the maximum distance between data points of both classes.\n",
    "\n",
    "\n",
    "<br/>\n",
    "<div><div style=\"float:left\"> <img src=\"images/fig-svm-1.png\" /> </div> <div> <img src=\"images/fig-svm-2.png\" /> </div> </div>\n",
    "\n",
    "\n",
    "To separate the two classes of data points, there are many possible hyperplanes that could be chosen. Our objective is to find a plane that has the maximum margin, i.e the maximum distance between data points of both classes. Maximizing the margin distance provides some reinforcement so that future data points can be classified with more confidence.\n",
    "\n",
    "<img src=\"images/fig-svm-3.jpg\" />\n",
    "\n",
    "### Support Vector\n",
    "\n",
    "The vector points closest to the hyperplane are known as the support vector points because only these two points are contributing to the result of the algorithm, other points are not. If a data point is not a support vector, removing it has no effect on the model. On the other hands, deleting the support vectors will then change the position of the hyperplane.\n",
    "\n",
    "### Margin\n",
    "\n",
    "The distance of the vectors from the hyperplane is called the margin which is a separation of a line to the closest class points. We would like to choose a hyperplane that maximises the margin between classes. The graph below shows what good margin and bad margin are.\n",
    "\n",
    "### Hyperplanes\n",
    "\n",
    "Hyperplanes are decision boundaries that help classify the data points. Data points falling on either side of the hyperplane can be attributed to different classes. Also, the dimension of the hyperplane depends upon the number of features. If the number of input features is 2, then the hyperplane is just a line. If the number of input features is 3, then the hyperplane becomes a two-dimensional plane. It becomes difficult to imagine when the number of features exceeds 3.\n",
    "\n",
    "\n",
    "Support vectors are data points that are closer to the hyperplane and influence the position and orientation of the hyperplane. Using these support vectors, we maximize the margin of the classifier. Deleting the support vectors will change the position of the hyperplane. These are the points that help us build our SVM.\n",
    "\n",
    "\n",
    "In order to find the maximal margin, we need to maximize the margin between the data points and the hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Basics\n",
    "\n",
    "### A **Vector** is an object that has both a magnitude and a direction.\n",
    "\n",
    "### Hyperplane\n",
    "A **hyperplane** is a higher-dimensional generalization of lines and planes. \n",
    "\n",
    "The equation of a hyperplane is \n",
    "$$ w ¬∑ x + b = 0$$ \n",
    "<br/>where $w$ is a vector normal to the hyperplane \n",
    "<br/>and $b$ is an offset. \n",
    "\n",
    "<img src=\"images/fig-svm-4.png\" />\n",
    "\n",
    "The magnitude (also called **norm**) of a vector x = $\\langle x_1,x_2, ..., x_n \\rangle$ is $ \\sqrt{x_1^2 + x_2^2 + ... + x_n^2}$ and is denoted $ \\begin{Vmatrix} x \\end{Vmatrix}$.\n",
    "\n",
    "$$ \\begin{Vmatrix} x \\end{Vmatrix} = \\sqrt{x_1^2 + x_2^2 + ... + x_n^2}$$\n",
    "\n",
    "        \n",
    "* #### Note that we can multiply by any constant and preserve the equality; if we multiply by  $\\frac{1}{\\begin{Vmatrix} w \\end{Vmatrix}}$, we get a new equation $ \\hat{w} . x + b^{'} = 0 $, where $ \\hat{w} = \\frac{w}{\\begin{Vmatrix} w \\end{Vmatrix}}$ is the **unit normal vector** and $ b^{'} = \\frac{b}{\\begin{Vmatrix} w \\end{Vmatrix}}$ is the distance from the hyperplane to the origin.\n",
    "\n",
    "* #### For any vector $x$ we can compute $ y = w ¬∑ x + b$. If $y = 0$, then $x$ is on the hyperplane. If $y > 0$, then $x$ is on one side of the hyperplane, and if $y < 0$, then $x$ is on the other side of the hyperplane. This will be useful when we are developing linear classifiers.\n",
    "\n",
    "\n",
    "\n",
    "More details here : https://courses.csail.mit.edu/6.034s/handouts/spring12/recitation10-LinearAlgebra.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "\n",
    "For Support Vector Classifier (SVC), we use $ w^{T}x + b $ where $w$ is the weight vector and $b$ is the bias.\n",
    "\n",
    "$$ w^{T}x + b = 0 $$\n",
    "\n",
    " \n",
    "<img src=\"images/fig-svm-5.png\" />\n",
    "<img src=\"images/fig-svm-6.png\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cost Function and Gradient Updates\n",
    "\n",
    "### <center>Maximizing-Margin is equivalent to Minimizing Loss.</center>\n",
    "\n",
    "\n",
    "In the SVM algorithm, we are looking to maximize the margin between the data points and the hyperplane. The loss function that helps maximize the margin is hinge loss.\n",
    "\n",
    "<img src=\"images/fig-svm-7.png\" />\n",
    "\n",
    "### Œª=1/C (C is always used for regularization coefficient)\n",
    "\n",
    "* The function of the first term, **hinge loss** is to penalize misclassifications. It measures the error due to **misclassification** (or data points being closer to the classification boundary than the margin).\n",
    "\n",
    "* The second term is the regularization term which is a technique to avoid overfitting by penalizing large coefficients in the solution vector. The Œª(lambda) is the regularization coefficient and its major role is to determine the trade-off between increasing the margin size and ensuring that the $x_i$ lies on the correct side of the margin.\n",
    "\n",
    "**\"Hinge\"** describes the fact that the error is 0 if the data point is classified correctly (and is not too close to the decision boundary).\n",
    "When the true class is -1 (as in your example), the hinge loss looks like this in the graph.\n",
    "\n",
    "### We need to minimise the above loss function to find the max-margin classifier.\n",
    "\n",
    "We can derive the formula for the margin from the hinge-loss. If a data point is on the margin of the classifier, the hinge-loss is exactly zero. Hence, on the margin, we have:\n",
    "\n",
    "<img src=\"images/fig-svm-8.png\" />\n",
    "\n",
    "Note that $ùë¶_i$ is either +1 or -1\n",
    "\n",
    "Therefore, we have:\n",
    "\n",
    "<img src=\"images/fig-svm-9.png\" />\n",
    "\n",
    "Our objective function is then:\n",
    "\n",
    "<img src=\"images/fig-svm-10.png\" />\n",
    "\n",
    "To minimize such an objection function, we should then use Lagrange Multiplier\n",
    "\n",
    "<img src=\"images/fig-svm-11.png\" />\n",
    "\n",
    "### SVM Under the hood\n",
    "In SVMs, our main objective is to select a hyperplane with the maximum possible margin between support vectors in the given dataset. SVM searches for the maximum margin hyperplane in the following 2 step process ‚Äì\n",
    "\n",
    "* 1. Generate hyperplanes which segregates the classes in the best possible way. There are many hyperplanes that might classify the data. We should look for the best hyperplane that represents the largest separation, or margin, between the two classes.\n",
    "\n",
    "* 2. So, we choose the hyperplane so that distance from it to the support vectors on each side is maximized. If such a hyperplane exists, it is known as the **maximum margin hyperplane** and the linear classifier it defines is known as a **maximum margin classifier**.\n",
    "\n",
    "\n",
    "### Problem with dispersed datasets\n",
    "Sometimes, the sample data points are so dispersed that it is not possible to separate them using a linear hyperplane. In such a situation, SVMs uses a kernel trick to transform the input space to a higher dimensional space as shown in the diagram below. It uses a mapping function to transform the 2-D input space into the 3-D input space. Now, we can easily segregate the data points using linear separation.\n",
    "\n",
    "<img src=\"images/fig-svm-12.png\" />\n",
    "\n",
    "SVM has a technique called the <a href=\"https://en.wikipedia.org/wiki/Kernel_method\" target=\"_blank\">kernel</a> trick. These are functions which take low dimensional input space and transform it into a higher-dimensional space i.e. it converts not separable problem to separable problem. It is mostly useful in non-linear separation problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "We'll use the built in breast cancer dataset from Scikit Learn. We can get with the load function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The data set is presented in a dictionary form:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'target_names', 'DESCR', 'feature_names', 'filename'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can grab information and arrays out of this dictionary to set up our data frame and understanding of the features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry \n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 3 is Mean Radius, field\n",
      "        13 is Radius SE, field 23 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n"
     ]
    }
   ],
   "source": [
    "print(cancer['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['mean radius', 'mean texture', 'mean perimeter', 'mean area',\n",
       "       'mean smoothness', 'mean compactness', 'mean concavity',\n",
       "       'mean concave points', 'mean symmetry', 'mean fractal dimension',\n",
       "       'radius error', 'texture error', 'perimeter error', 'area error',\n",
       "       'smoothness error', 'compactness error', 'concavity error',\n",
       "       'concave points error', 'symmetry error',\n",
       "       'fractal dimension error', 'worst radius', 'worst texture',\n",
       "       'worst perimeter', 'worst area', 'worst smoothness',\n",
       "       'worst compactness', 'worst concavity', 'worst concave points',\n",
       "       'worst symmetry', 'worst fractal dimension'], dtype='<U23')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['feature_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>12.45</td>\n",
       "      <td>15.70</td>\n",
       "      <td>82.57</td>\n",
       "      <td>477.1</td>\n",
       "      <td>0.12780</td>\n",
       "      <td>0.17000</td>\n",
       "      <td>0.15780</td>\n",
       "      <td>0.08089</td>\n",
       "      <td>0.2087</td>\n",
       "      <td>0.07613</td>\n",
       "      <td>...</td>\n",
       "      <td>15.47</td>\n",
       "      <td>23.75</td>\n",
       "      <td>103.40</td>\n",
       "      <td>741.6</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.5249</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.1741</td>\n",
       "      <td>0.3985</td>\n",
       "      <td>0.12440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>18.25</td>\n",
       "      <td>19.98</td>\n",
       "      <td>119.60</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>0.09463</td>\n",
       "      <td>0.10900</td>\n",
       "      <td>0.11270</td>\n",
       "      <td>0.07400</td>\n",
       "      <td>0.1794</td>\n",
       "      <td>0.05742</td>\n",
       "      <td>...</td>\n",
       "      <td>22.88</td>\n",
       "      <td>27.66</td>\n",
       "      <td>153.20</td>\n",
       "      <td>1606.0</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.3784</td>\n",
       "      <td>0.1932</td>\n",
       "      <td>0.3063</td>\n",
       "      <td>0.08368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13.71</td>\n",
       "      <td>20.83</td>\n",
       "      <td>90.20</td>\n",
       "      <td>577.9</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0.16450</td>\n",
       "      <td>0.09366</td>\n",
       "      <td>0.05985</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07451</td>\n",
       "      <td>...</td>\n",
       "      <td>17.06</td>\n",
       "      <td>28.14</td>\n",
       "      <td>110.60</td>\n",
       "      <td>897.0</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.3682</td>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.1556</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.11510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>13.00</td>\n",
       "      <td>21.82</td>\n",
       "      <td>87.50</td>\n",
       "      <td>519.8</td>\n",
       "      <td>0.12730</td>\n",
       "      <td>0.19320</td>\n",
       "      <td>0.18590</td>\n",
       "      <td>0.09353</td>\n",
       "      <td>0.2350</td>\n",
       "      <td>0.07389</td>\n",
       "      <td>...</td>\n",
       "      <td>15.49</td>\n",
       "      <td>30.73</td>\n",
       "      <td>106.20</td>\n",
       "      <td>739.3</td>\n",
       "      <td>0.1703</td>\n",
       "      <td>0.5401</td>\n",
       "      <td>0.5390</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.4378</td>\n",
       "      <td>0.10720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>12.46</td>\n",
       "      <td>24.04</td>\n",
       "      <td>83.97</td>\n",
       "      <td>475.9</td>\n",
       "      <td>0.11860</td>\n",
       "      <td>0.23960</td>\n",
       "      <td>0.22730</td>\n",
       "      <td>0.08543</td>\n",
       "      <td>0.2030</td>\n",
       "      <td>0.08243</td>\n",
       "      <td>...</td>\n",
       "      <td>15.09</td>\n",
       "      <td>40.68</td>\n",
       "      <td>97.65</td>\n",
       "      <td>711.4</td>\n",
       "      <td>0.1853</td>\n",
       "      <td>1.0580</td>\n",
       "      <td>1.1050</td>\n",
       "      <td>0.2210</td>\n",
       "      <td>0.4366</td>\n",
       "      <td>0.20750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0        17.99         10.38          122.80     1001.0          0.11840   \n",
       "1        20.57         17.77          132.90     1326.0          0.08474   \n",
       "2        19.69         21.25          130.00     1203.0          0.10960   \n",
       "3        11.42         20.38           77.58      386.1          0.14250   \n",
       "4        20.29         14.34          135.10     1297.0          0.10030   \n",
       "5        12.45         15.70           82.57      477.1          0.12780   \n",
       "6        18.25         19.98          119.60     1040.0          0.09463   \n",
       "7        13.71         20.83           90.20      577.9          0.11890   \n",
       "8        13.00         21.82           87.50      519.8          0.12730   \n",
       "9        12.46         24.04           83.97      475.9          0.11860   \n",
       "\n",
       "   mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0           0.27760         0.30010              0.14710         0.2419   \n",
       "1           0.07864         0.08690              0.07017         0.1812   \n",
       "2           0.15990         0.19740              0.12790         0.2069   \n",
       "3           0.28390         0.24140              0.10520         0.2597   \n",
       "4           0.13280         0.19800              0.10430         0.1809   \n",
       "5           0.17000         0.15780              0.08089         0.2087   \n",
       "6           0.10900         0.11270              0.07400         0.1794   \n",
       "7           0.16450         0.09366              0.05985         0.2196   \n",
       "8           0.19320         0.18590              0.09353         0.2350   \n",
       "9           0.23960         0.22730              0.08543         0.2030   \n",
       "\n",
       "   mean fractal dimension  ...  worst radius  worst texture  worst perimeter  \\\n",
       "0                 0.07871  ...         25.38          17.33           184.60   \n",
       "1                 0.05667  ...         24.99          23.41           158.80   \n",
       "2                 0.05999  ...         23.57          25.53           152.50   \n",
       "3                 0.09744  ...         14.91          26.50            98.87   \n",
       "4                 0.05883  ...         22.54          16.67           152.20   \n",
       "5                 0.07613  ...         15.47          23.75           103.40   \n",
       "6                 0.05742  ...         22.88          27.66           153.20   \n",
       "7                 0.07451  ...         17.06          28.14           110.60   \n",
       "8                 0.07389  ...         15.49          30.73           106.20   \n",
       "9                 0.08243  ...         15.09          40.68            97.65   \n",
       "\n",
       "   worst area  worst smoothness  worst compactness  worst concavity  \\\n",
       "0      2019.0            0.1622             0.6656           0.7119   \n",
       "1      1956.0            0.1238             0.1866           0.2416   \n",
       "2      1709.0            0.1444             0.4245           0.4504   \n",
       "3       567.7            0.2098             0.8663           0.6869   \n",
       "4      1575.0            0.1374             0.2050           0.4000   \n",
       "5       741.6            0.1791             0.5249           0.5355   \n",
       "6      1606.0            0.1442             0.2576           0.3784   \n",
       "7       897.0            0.1654             0.3682           0.2678   \n",
       "8       739.3            0.1703             0.5401           0.5390   \n",
       "9       711.4            0.1853             1.0580           1.1050   \n",
       "\n",
       "   worst concave points  worst symmetry  worst fractal dimension  \n",
       "0                0.2654          0.4601                  0.11890  \n",
       "1                0.1860          0.2750                  0.08902  \n",
       "2                0.2430          0.3613                  0.08758  \n",
       "3                0.2575          0.6638                  0.17300  \n",
       "4                0.1625          0.2364                  0.07678  \n",
       "5                0.1741          0.3985                  0.12440  \n",
       "6                0.1932          0.3063                  0.08368  \n",
       "7                0.1556          0.3196                  0.11510  \n",
       "8                0.2060          0.4378                  0.10720  \n",
       "9                0.2210          0.4366                  0.20750  \n",
       "\n",
       "[10 rows x 30 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "df_feat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      "mean radius                569 non-null float64\n",
      "mean texture               569 non-null float64\n",
      "mean perimeter             569 non-null float64\n",
      "mean area                  569 non-null float64\n",
      "mean smoothness            569 non-null float64\n",
      "mean compactness           569 non-null float64\n",
      "mean concavity             569 non-null float64\n",
      "mean concave points        569 non-null float64\n",
      "mean symmetry              569 non-null float64\n",
      "mean fractal dimension     569 non-null float64\n",
      "radius error               569 non-null float64\n",
      "texture error              569 non-null float64\n",
      "perimeter error            569 non-null float64\n",
      "area error                 569 non-null float64\n",
      "smoothness error           569 non-null float64\n",
      "compactness error          569 non-null float64\n",
      "concavity error            569 non-null float64\n",
      "concave points error       569 non-null float64\n",
      "symmetry error             569 non-null float64\n",
      "fractal dimension error    569 non-null float64\n",
      "worst radius               569 non-null float64\n",
      "worst texture              569 non-null float64\n",
      "worst perimeter            569 non-null float64\n",
      "worst area                 569 non-null float64\n",
      "worst smoothness           569 non-null float64\n",
      "worst compactness          569 non-null float64\n",
      "worst concavity            569 non-null float64\n",
      "worst concave points       569 non-null float64\n",
      "worst symmetry             569 non-null float64\n",
      "worst fractal dimension    569 non-null float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df_feat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows √ó 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Cancer\n",
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "..      ...\n",
       "564       0\n",
       "565       0\n",
       "566       0\n",
       "567       0\n",
       "568       1\n",
       "\n",
       "[569 rows x 1 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_target = pd.DataFrame(cancer['target'],columns=['Cancer'])\n",
    "df_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    357\n",
       "0    212\n",
       "Name: Cancer, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check distribution of target_class column\n",
    "df_target['Cancer'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.627417\n",
       "0    0.372583\n",
       "Name: Cancer, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view the percentage distribution of target_class column\n",
    "df_target['Cancer'].value_counts()/np.float(len(df_target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_feat, np.ravel(df_target), test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ravel(df_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = SVC(gamma='auto')\n",
    "'''\n",
    "Init signature:\n",
    "svm.SVC(\n",
    "    C=1.0,\n",
    "    kernel='rbf',\n",
    "    degree=3,\n",
    "    gamma='auto_deprecated',\n",
    "    coef0=0.0,\n",
    "    shrinking=True,\n",
    "    probability=False,\n",
    "    tol=0.001,\n",
    "    cache_size=200,\n",
    "    class_weight=None,\n",
    "    verbose=False,\n",
    "    max_iter=-1,\n",
    "    decision_function_shape='ovr',\n",
    "    random_state=None,\n",
    ")\n",
    "'''\n",
    "# model = svm.SVC(C=1.0, kernel='rbf', gamma=0.01)\n",
    "model = SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations\n",
    "\n",
    "Now let's predict using the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0  66]\n",
      " [  0 105]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        66\n",
      "           1       0.61      1.00      0.76       105\n",
      "\n",
      "    accuracy                           0.61       171\n",
      "   macro avg       0.31      0.50      0.38       171\n",
      "weighted avg       0.38      0.61      0.47       171\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinesh/anaconda3/lib/python3.7/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import metrics to compute accuracy\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with default hyperparameters: 0.6140\n"
     ]
    }
   ],
   "source": [
    "# compute and print accuracy score\n",
    "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Woah! Notice that we are classifying everything into a single class! This means our model needs to have it parameters adjusted (it may also help to normalize the data).\n",
    "\n",
    "We can search for parameters using a GridSearch!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridsearch\n",
    "\n",
    "Finding the right parameters (like what C or gamma values to use) is a tricky task! But luckily, we can be a little lazy and just try a bunch of combinations and see what works best! This idea of creating a 'grid' of parameters and just trying out all the possible combinations is called a Gridsearch, this method is common enough that Scikit-learn has this functionality built in with GridSearchCV! The CV stands for cross-validation which is the\n",
    "\n",
    "GridSearchCV takes a dictionary that describes the parameters that should be tried and a model to train. The grid of parameters is defined as a dictionary, where the keys are the parameters and the values are the settings to be tested. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1,1, 10, 100, 1000], 'gamma': [1,0.1,0.01,0.001,0.0001], 'kernel': ['rbf']} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the great things about GridSearchCV is that it is a meta-estimator. It takes an estimator like SVC, and creates a new estimator, that behaves exactly the same - in this case, like a classifier. You should add refit=True and choose verbose to whatever number you want, higher the number, the more verbose (verbose just means the text output describing the process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Init signature:\n",
    "GridSearchCV(\n",
    "    estimator,\n",
    "    param_grid,\n",
    "    scoring=None,\n",
    "    n_jobs=None,\n",
    "    iid='warn',\n",
    "    refit=True,\n",
    "    cv='warn',\n",
    "    verbose=0,\n",
    "    pre_dispatch='2*n_jobs',\n",
    "    error_score='raise-deprecating',\n",
    "    return_train_score=False,\n",
    ")\n",
    "Docstring:     \n",
    "Exhaustive search over specified parameter values for an estimator.\n",
    "\n",
    "Important members are fit, predict.\n",
    "\"\"\"\n",
    "\n",
    "grid = GridSearchCV(SVC(),param_grid,refit=True,verbose=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What fit does is a bit more involved then usual. First, it runs the same loop with cross-validation, to find the best parameter combination. Once it has the best combination, it runs fit again on all data passed to fit (without cross-validation), to built a single new model using the best parameter setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dinesh/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_split.py:1978: FutureWarning: The default value of cv will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 25 candidates, totalling 75 fits\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=0.1, gamma=1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=0.1, gamma=0.1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=0.1, gamma=0.01, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=0.1, gamma=0.001, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.902, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=0.1, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=0.1, gamma=0.0001, kernel=rbf, score=0.917, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=1, kernel=rbf ........................................\n",
      "[CV] ............ C=1, gamma=1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=0.1, kernel=rbf ......................................\n",
      "[CV] .......... C=1, gamma=0.1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1, gamma=0.01, kernel=rbf .....................................\n",
      "[CV] ......... C=1, gamma=0.01, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.902, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.940, total=   0.0s\n",
      "[CV] C=1, gamma=0.001, kernel=rbf ....................................\n",
      "[CV] ........ C=1, gamma=0.001, kernel=rbf, score=0.955, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.940, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.970, total=   0.0s\n",
      "[CV] C=1, gamma=0.0001, kernel=rbf ...................................\n",
      "[CV] ....... C=1, gamma=0.0001, kernel=rbf, score=0.947, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=1, kernel=rbf .......................................\n",
      "[CV] ........... C=10, gamma=1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=0.1, kernel=rbf .....................................\n",
      "[CV] ......... C=10, gamma=0.1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=10, gamma=0.01, kernel=rbf ....................................\n",
      "[CV] ........ C=10, gamma=0.01, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.895, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.932, total=   0.0s\n",
      "[CV] C=10, gamma=0.001, kernel=rbf ...................................\n",
      "[CV] ....... C=10, gamma=0.001, kernel=rbf, score=0.917, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.932, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.970, total=   0.0s\n",
      "[CV] C=10, gamma=0.0001, kernel=rbf ..................................\n",
      "[CV] ...... C=10, gamma=0.0001, kernel=rbf, score=0.962, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=1, kernel=rbf ......................................\n",
      "[CV] .......... C=100, gamma=1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=0.1, kernel=rbf ....................................\n",
      "[CV] ........ C=100, gamma=0.1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=100, gamma=0.01, kernel=rbf ...................................\n",
      "[CV] ....... C=100, gamma=0.01, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.895, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.932, total=   0.0s\n",
      "[CV] C=100, gamma=0.001, kernel=rbf ..................................\n",
      "[CV] ...... C=100, gamma=0.001, kernel=rbf, score=0.917, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.917, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.977, total=   0.0s\n",
      "[CV] C=100, gamma=0.0001, kernel=rbf .................................\n",
      "[CV] ..... C=100, gamma=0.0001, kernel=rbf, score=0.939, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=1, kernel=rbf .....................................\n",
      "[CV] ......... C=1000, gamma=1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n",
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.1, kernel=rbf ...................................\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ....... C=1000, gamma=0.1, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.632, total=   0.0s\n",
      "[CV] C=1000, gamma=0.01, kernel=rbf ..................................\n",
      "[CV] ...... C=1000, gamma=0.01, kernel=rbf, score=0.636, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.895, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.932, total=   0.0s\n",
      "[CV] C=1000, gamma=0.001, kernel=rbf .................................\n",
      "[CV] ..... C=1000, gamma=0.001, kernel=rbf, score=0.917, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.910, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.970, total=   0.0s\n",
      "[CV] C=1000, gamma=0.0001, kernel=rbf ................................\n",
      "[CV] .... C=1000, gamma=0.0001, kernel=rbf, score=0.932, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  75 out of  75 | elapsed:    1.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'C': [0.1, 1, 10, 100, 1000],\n",
       "                         'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
       "                         'kernel': ['rbf']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=3)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May take awhile!\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can inspect the best parameters found by GridSearchCV in the best_params_ attribute, and the best estimator in the best\\_estimator_ attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=10, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma=0.0001, kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then you can re-run predictions on this grid object just like you would with a normal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_predictions = grid.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix\n",
      "\n",
      " [[ 60   6]\n",
      " [  3 102]]\n",
      "\n",
      "True Positives(TP) =  60\n",
      "\n",
      "True Negatives(TN) =  102\n",
      "\n",
      "False Positives(FP) =  6\n",
      "\n",
      "False Negatives(FN) =  3\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test,grid_predictions)\n",
    "\n",
    "TP = cm[0,0]\n",
    "TN = cm[1,1]\n",
    "FP = cm[0,1]\n",
    "FN = cm[1,0]\n",
    "\n",
    "print('Confusion matrix\\n\\n', cm)\n",
    "\n",
    "print('\\nTrue Positives(TP) = ', TP)\n",
    "\n",
    "print('\\nTrue Negatives(TN) = ', TN)\n",
    "\n",
    "print('\\nFalse Positives(FP) = ', FP)\n",
    "\n",
    "print('\\nFalse Negatives(FN) = ', FN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7ff48cf4a4d0>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize confusion matrix with seaborn heatmap\n",
    "\n",
    "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
    "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
    "\n",
    "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93        66\n",
      "           1       0.94      0.97      0.96       105\n",
      "\n",
      "    accuracy                           0.95       171\n",
      "   macro avg       0.95      0.94      0.94       171\n",
      "weighted avg       0.95      0.95      0.95       171\n",
      "\n",
      "[[ 60   6]\n",
      " [  3 102]]\n",
      "Accuracy of the model: 0.95\n"
     ]
    }
   ],
   "source": [
    "# print(classification_report(y_test,grid_predictions))\n",
    "\n",
    "# Measuring accuracy on Testing Data\n",
    "print(classification_report(y_test, grid_predictions))\n",
    "print(confusion_matrix(y_test, grid_predictions))\n",
    "\n",
    "# Printing the Overall Accuracy of the model\n",
    "F1_Score=classification_report(y_test, grid_predictions).split()[-2]\n",
    "print('Accuracy of the model:', F1_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ROC - AUC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot ROC Curve\n",
    "\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "fpr, tpr, thresholds = roc_curve(y_test, grid_predictions)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, linewidth=2)\n",
    "plt.plot([0,1], [0,1], 'k--' )\n",
    "plt.rcParams['font.size'] = 12\n",
    "plt.title('ROC curve for Predicting a breast cancer classifier')\n",
    "plt.xlabel('False Positive Rate (1 - Specificity)')\n",
    "plt.ylabel('True Positive Rate (Sensitivity)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model accuracy score with {'C': 10, 'gamma': 0.0001, 'kernel': 'rbf'} hyperparameters:0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "# compute and print accuracy score\n",
    "print('Model accuracy score with {} hyperparameters:{}'.\n",
    "      format(grid.best_params_,accuracy_score(y_test, grid_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check for overfitting and underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score: 0.9698\n",
      "Test set score: 0.9474\n"
     ]
    }
   ],
   "source": [
    "# print the scores on training and test set\n",
    "\n",
    "print('Training set score: {:.4f}'.format(grid.score(X_train, y_train)))\n",
    "\n",
    "print('Test set score: {:.4f}'.format(grid.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>TargetColumn</th>\n",
       "      <th>PredictedCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>12.360</td>\n",
       "      <td>18.54</td>\n",
       "      <td>79.01</td>\n",
       "      <td>466.7</td>\n",
       "      <td>0.08477</td>\n",
       "      <td>0.06815</td>\n",
       "      <td>0.02643</td>\n",
       "      <td>0.01921</td>\n",
       "      <td>0.1602</td>\n",
       "      <td>0.06066</td>\n",
       "      <td>...</td>\n",
       "      <td>85.56</td>\n",
       "      <td>544.1</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.19630</td>\n",
       "      <td>0.19370</td>\n",
       "      <td>0.08442</td>\n",
       "      <td>0.2983</td>\n",
       "      <td>0.07185</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>437</td>\n",
       "      <td>14.040</td>\n",
       "      <td>15.98</td>\n",
       "      <td>89.78</td>\n",
       "      <td>611.2</td>\n",
       "      <td>0.08458</td>\n",
       "      <td>0.05895</td>\n",
       "      <td>0.03534</td>\n",
       "      <td>0.02944</td>\n",
       "      <td>0.1714</td>\n",
       "      <td>0.05898</td>\n",
       "      <td>...</td>\n",
       "      <td>101.20</td>\n",
       "      <td>750.0</td>\n",
       "      <td>0.11950</td>\n",
       "      <td>0.12520</td>\n",
       "      <td>0.11170</td>\n",
       "      <td>0.07453</td>\n",
       "      <td>0.2725</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>12.910</td>\n",
       "      <td>16.33</td>\n",
       "      <td>82.53</td>\n",
       "      <td>516.4</td>\n",
       "      <td>0.07941</td>\n",
       "      <td>0.05366</td>\n",
       "      <td>0.03873</td>\n",
       "      <td>0.02377</td>\n",
       "      <td>0.1829</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>90.81</td>\n",
       "      <td>600.6</td>\n",
       "      <td>0.10970</td>\n",
       "      <td>0.15060</td>\n",
       "      <td>0.17640</td>\n",
       "      <td>0.08235</td>\n",
       "      <td>0.3024</td>\n",
       "      <td>0.06949</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>16.110</td>\n",
       "      <td>18.05</td>\n",
       "      <td>105.10</td>\n",
       "      <td>813.0</td>\n",
       "      <td>0.09721</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.09447</td>\n",
       "      <td>0.05943</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.06248</td>\n",
       "      <td>...</td>\n",
       "      <td>129.00</td>\n",
       "      <td>1233.0</td>\n",
       "      <td>0.13140</td>\n",
       "      <td>0.22360</td>\n",
       "      <td>0.28020</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.2792</td>\n",
       "      <td>0.08158</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>319</td>\n",
       "      <td>12.430</td>\n",
       "      <td>17.00</td>\n",
       "      <td>78.60</td>\n",
       "      <td>477.3</td>\n",
       "      <td>0.07557</td>\n",
       "      <td>0.03454</td>\n",
       "      <td>0.01342</td>\n",
       "      <td>0.01699</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.05561</td>\n",
       "      <td>...</td>\n",
       "      <td>81.76</td>\n",
       "      <td>515.9</td>\n",
       "      <td>0.08409</td>\n",
       "      <td>0.04712</td>\n",
       "      <td>0.02237</td>\n",
       "      <td>0.02832</td>\n",
       "      <td>0.1901</td>\n",
       "      <td>0.05932</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>295</td>\n",
       "      <td>13.770</td>\n",
       "      <td>13.27</td>\n",
       "      <td>88.06</td>\n",
       "      <td>582.7</td>\n",
       "      <td>0.09198</td>\n",
       "      <td>0.06221</td>\n",
       "      <td>0.01063</td>\n",
       "      <td>0.01917</td>\n",
       "      <td>0.1592</td>\n",
       "      <td>0.05912</td>\n",
       "      <td>...</td>\n",
       "      <td>94.17</td>\n",
       "      <td>661.1</td>\n",
       "      <td>0.11700</td>\n",
       "      <td>0.10720</td>\n",
       "      <td>0.03732</td>\n",
       "      <td>0.05802</td>\n",
       "      <td>0.2823</td>\n",
       "      <td>0.06794</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>8.726</td>\n",
       "      <td>15.83</td>\n",
       "      <td>55.84</td>\n",
       "      <td>230.9</td>\n",
       "      <td>0.11500</td>\n",
       "      <td>0.08201</td>\n",
       "      <td>0.04132</td>\n",
       "      <td>0.01924</td>\n",
       "      <td>0.1649</td>\n",
       "      <td>0.07633</td>\n",
       "      <td>...</td>\n",
       "      <td>64.48</td>\n",
       "      <td>284.4</td>\n",
       "      <td>0.17240</td>\n",
       "      <td>0.23640</td>\n",
       "      <td>0.24560</td>\n",
       "      <td>0.10500</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.10170</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>23.290</td>\n",
       "      <td>26.67</td>\n",
       "      <td>158.90</td>\n",
       "      <td>1685.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.20840</td>\n",
       "      <td>0.35230</td>\n",
       "      <td>0.16200</td>\n",
       "      <td>0.2200</td>\n",
       "      <td>0.06229</td>\n",
       "      <td>...</td>\n",
       "      <td>177.00</td>\n",
       "      <td>1986.0</td>\n",
       "      <td>0.15360</td>\n",
       "      <td>0.41670</td>\n",
       "      <td>0.78920</td>\n",
       "      <td>0.27330</td>\n",
       "      <td>0.3198</td>\n",
       "      <td>0.08762</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>268</td>\n",
       "      <td>12.870</td>\n",
       "      <td>16.21</td>\n",
       "      <td>82.38</td>\n",
       "      <td>512.2</td>\n",
       "      <td>0.09425</td>\n",
       "      <td>0.06219</td>\n",
       "      <td>0.03900</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.2010</td>\n",
       "      <td>0.05769</td>\n",
       "      <td>...</td>\n",
       "      <td>89.27</td>\n",
       "      <td>597.5</td>\n",
       "      <td>0.12560</td>\n",
       "      <td>0.18080</td>\n",
       "      <td>0.19920</td>\n",
       "      <td>0.05780</td>\n",
       "      <td>0.3604</td>\n",
       "      <td>0.07062</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>342</td>\n",
       "      <td>11.060</td>\n",
       "      <td>14.96</td>\n",
       "      <td>71.49</td>\n",
       "      <td>373.9</td>\n",
       "      <td>0.10330</td>\n",
       "      <td>0.09097</td>\n",
       "      <td>0.05397</td>\n",
       "      <td>0.03341</td>\n",
       "      <td>0.1776</td>\n",
       "      <td>0.06907</td>\n",
       "      <td>...</td>\n",
       "      <td>79.76</td>\n",
       "      <td>440.0</td>\n",
       "      <td>0.14180</td>\n",
       "      <td>0.22100</td>\n",
       "      <td>0.22990</td>\n",
       "      <td>0.10750</td>\n",
       "      <td>0.3301</td>\n",
       "      <td>0.09080</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "107       12.360         18.54           79.01      466.7          0.08477   \n",
       "437       14.040         15.98           89.78      611.2          0.08458   \n",
       "195       12.910         16.33           82.53      516.4          0.07941   \n",
       "141       16.110         18.05          105.10      813.0          0.09721   \n",
       "319       12.430         17.00           78.60      477.3          0.07557   \n",
       "295       13.770         13.27           88.06      582.7          0.09198   \n",
       "114        8.726         15.83           55.84      230.9          0.11500   \n",
       "202       23.290         26.67          158.90     1685.0          0.11410   \n",
       "268       12.870         16.21           82.38      512.2          0.09425   \n",
       "342       11.060         14.96           71.49      373.9          0.10330   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "107           0.06815         0.02643              0.01921         0.1602   \n",
       "437           0.05895         0.03534              0.02944         0.1714   \n",
       "195           0.05366         0.03873              0.02377         0.1829   \n",
       "141           0.11370         0.09447              0.05943         0.1861   \n",
       "319           0.03454         0.01342              0.01699         0.1472   \n",
       "295           0.06221         0.01063              0.01917         0.1592   \n",
       "114           0.08201         0.04132              0.01924         0.1649   \n",
       "202           0.20840         0.35230              0.16200         0.2200   \n",
       "268           0.06219         0.03900              0.01615         0.2010   \n",
       "342           0.09097         0.05397              0.03341         0.1776   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "107                 0.06066  ...            85.56       544.1   \n",
       "437                 0.05898  ...           101.20       750.0   \n",
       "195                 0.05667  ...            90.81       600.6   \n",
       "141                 0.06248  ...           129.00      1233.0   \n",
       "319                 0.05561  ...            81.76       515.9   \n",
       "295                 0.05912  ...            94.17       661.1   \n",
       "114                 0.07633  ...            64.48       284.4   \n",
       "202                 0.06229  ...           177.00      1986.0   \n",
       "268                 0.05769  ...            89.27       597.5   \n",
       "342                 0.06907  ...            79.76       440.0   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "107           0.11840            0.19630          0.19370   \n",
       "437           0.11950            0.12520          0.11170   \n",
       "195           0.10970            0.15060          0.17640   \n",
       "141           0.13140            0.22360          0.28020   \n",
       "319           0.08409            0.04712          0.02237   \n",
       "295           0.11700            0.10720          0.03732   \n",
       "114           0.17240            0.23640          0.24560   \n",
       "202           0.15360            0.41670          0.78920   \n",
       "268           0.12560            0.18080          0.19920   \n",
       "342           0.14180            0.22100          0.22990   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "107               0.08442          0.2983                  0.07185   \n",
       "437               0.07453          0.2725                  0.07234   \n",
       "195               0.08235          0.3024                  0.06949   \n",
       "141               0.12160          0.2792                  0.08158   \n",
       "319               0.02832          0.1901                  0.05932   \n",
       "295               0.05802          0.2823                  0.06794   \n",
       "114               0.10500          0.2926                  0.10170   \n",
       "202               0.27330          0.3198                  0.08762   \n",
       "268               0.05780          0.3604                  0.07062   \n",
       "342               0.10750          0.3301                  0.09080   \n",
       "\n",
       "     TargetColumn  PredictedCancer  \n",
       "107             1                1  \n",
       "437             1                1  \n",
       "195             1                1  \n",
       "141             0                0  \n",
       "319             1                1  \n",
       "295             1                1  \n",
       "114             1                1  \n",
       "202             0                0  \n",
       "268             1                1  \n",
       "342             1                1  \n",
       "\n",
       "[10 rows x 32 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing some sample values of prediction\n",
    "TestingDataResults=pd.DataFrame(data=X_test)\n",
    "TestingDataResults['TargetColumn']=y_test\n",
    "TestingDataResults['PredictedCancer']=grid_predictions\n",
    "TestingDataResults.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>TargetColumn</th>\n",
       "      <th>PredictedCancer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>385</td>\n",
       "      <td>14.60</td>\n",
       "      <td>23.29</td>\n",
       "      <td>93.97</td>\n",
       "      <td>664.7</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.06636</td>\n",
       "      <td>0.08390</td>\n",
       "      <td>0.05271</td>\n",
       "      <td>0.1627</td>\n",
       "      <td>0.05416</td>\n",
       "      <td>...</td>\n",
       "      <td>102.20</td>\n",
       "      <td>758.2</td>\n",
       "      <td>0.13120</td>\n",
       "      <td>0.15810</td>\n",
       "      <td>0.2675</td>\n",
       "      <td>0.13590</td>\n",
       "      <td>0.2477</td>\n",
       "      <td>0.06836</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>379</td>\n",
       "      <td>11.08</td>\n",
       "      <td>18.83</td>\n",
       "      <td>73.30</td>\n",
       "      <td>361.6</td>\n",
       "      <td>0.12160</td>\n",
       "      <td>0.21540</td>\n",
       "      <td>0.16890</td>\n",
       "      <td>0.06367</td>\n",
       "      <td>0.2196</td>\n",
       "      <td>0.07950</td>\n",
       "      <td>...</td>\n",
       "      <td>91.76</td>\n",
       "      <td>508.1</td>\n",
       "      <td>0.21840</td>\n",
       "      <td>0.93790</td>\n",
       "      <td>0.8402</td>\n",
       "      <td>0.25240</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.14030</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>14.86</td>\n",
       "      <td>23.21</td>\n",
       "      <td>100.40</td>\n",
       "      <td>671.4</td>\n",
       "      <td>0.10440</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.16970</td>\n",
       "      <td>0.08878</td>\n",
       "      <td>0.1737</td>\n",
       "      <td>0.06672</td>\n",
       "      <td>...</td>\n",
       "      <td>118.60</td>\n",
       "      <td>784.7</td>\n",
       "      <td>0.13160</td>\n",
       "      <td>0.46480</td>\n",
       "      <td>0.4589</td>\n",
       "      <td>0.17270</td>\n",
       "      <td>0.3000</td>\n",
       "      <td>0.08701</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>476</td>\n",
       "      <td>14.20</td>\n",
       "      <td>20.53</td>\n",
       "      <td>92.41</td>\n",
       "      <td>618.4</td>\n",
       "      <td>0.08931</td>\n",
       "      <td>0.11080</td>\n",
       "      <td>0.05063</td>\n",
       "      <td>0.03058</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.06009</td>\n",
       "      <td>...</td>\n",
       "      <td>112.10</td>\n",
       "      <td>828.5</td>\n",
       "      <td>0.11530</td>\n",
       "      <td>0.34290</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.13390</td>\n",
       "      <td>0.2534</td>\n",
       "      <td>0.07858</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>16.84</td>\n",
       "      <td>19.46</td>\n",
       "      <td>108.40</td>\n",
       "      <td>880.2</td>\n",
       "      <td>0.07445</td>\n",
       "      <td>0.07223</td>\n",
       "      <td>0.05150</td>\n",
       "      <td>0.02771</td>\n",
       "      <td>0.1844</td>\n",
       "      <td>0.05268</td>\n",
       "      <td>...</td>\n",
       "      <td>120.30</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>0.08774</td>\n",
       "      <td>0.17100</td>\n",
       "      <td>0.1882</td>\n",
       "      <td>0.08436</td>\n",
       "      <td>0.2527</td>\n",
       "      <td>0.05972</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>363</td>\n",
       "      <td>16.50</td>\n",
       "      <td>18.29</td>\n",
       "      <td>106.60</td>\n",
       "      <td>838.1</td>\n",
       "      <td>0.09686</td>\n",
       "      <td>0.08468</td>\n",
       "      <td>0.05862</td>\n",
       "      <td>0.04835</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.05593</td>\n",
       "      <td>...</td>\n",
       "      <td>117.20</td>\n",
       "      <td>1009.0</td>\n",
       "      <td>0.13380</td>\n",
       "      <td>0.16790</td>\n",
       "      <td>0.1663</td>\n",
       "      <td>0.09123</td>\n",
       "      <td>0.2394</td>\n",
       "      <td>0.06469</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>536</td>\n",
       "      <td>14.27</td>\n",
       "      <td>22.55</td>\n",
       "      <td>93.77</td>\n",
       "      <td>629.8</td>\n",
       "      <td>0.10380</td>\n",
       "      <td>0.11540</td>\n",
       "      <td>0.14630</td>\n",
       "      <td>0.06139</td>\n",
       "      <td>0.1926</td>\n",
       "      <td>0.05982</td>\n",
       "      <td>...</td>\n",
       "      <td>104.30</td>\n",
       "      <td>728.3</td>\n",
       "      <td>0.13800</td>\n",
       "      <td>0.27330</td>\n",
       "      <td>0.4234</td>\n",
       "      <td>0.13620</td>\n",
       "      <td>0.2698</td>\n",
       "      <td>0.08351</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>15.37</td>\n",
       "      <td>22.76</td>\n",
       "      <td>100.20</td>\n",
       "      <td>728.2</td>\n",
       "      <td>0.09200</td>\n",
       "      <td>0.10360</td>\n",
       "      <td>0.11220</td>\n",
       "      <td>0.07483</td>\n",
       "      <td>0.1717</td>\n",
       "      <td>0.06097</td>\n",
       "      <td>...</td>\n",
       "      <td>107.50</td>\n",
       "      <td>830.9</td>\n",
       "      <td>0.12570</td>\n",
       "      <td>0.19970</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.14760</td>\n",
       "      <td>0.2556</td>\n",
       "      <td>0.06828</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>297</td>\n",
       "      <td>11.76</td>\n",
       "      <td>18.14</td>\n",
       "      <td>75.00</td>\n",
       "      <td>431.1</td>\n",
       "      <td>0.09968</td>\n",
       "      <td>0.05914</td>\n",
       "      <td>0.02685</td>\n",
       "      <td>0.03515</td>\n",
       "      <td>0.1619</td>\n",
       "      <td>0.06287</td>\n",
       "      <td>...</td>\n",
       "      <td>85.10</td>\n",
       "      <td>553.6</td>\n",
       "      <td>0.11370</td>\n",
       "      <td>0.07974</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.07160</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.06915</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows √ó 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "385        14.60         23.29           93.97      664.7          0.08682   \n",
       "379        11.08         18.83           73.30      361.6          0.12160   \n",
       "194        14.86         23.21          100.40      671.4          0.10440   \n",
       "476        14.20         20.53           92.41      618.4          0.08931   \n",
       "157        16.84         19.46          108.40      880.2          0.07445   \n",
       "363        16.50         18.29          106.60      838.1          0.09686   \n",
       "536        14.27         22.55           93.77      629.8          0.10380   \n",
       "91         15.37         22.76          100.20      728.2          0.09200   \n",
       "297        11.76         18.14           75.00      431.1          0.09968   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "385           0.06636         0.08390              0.05271         0.1627   \n",
       "379           0.21540         0.16890              0.06367         0.2196   \n",
       "194           0.19800         0.16970              0.08878         0.1737   \n",
       "476           0.11080         0.05063              0.03058         0.1506   \n",
       "157           0.07223         0.05150              0.02771         0.1844   \n",
       "363           0.08468         0.05862              0.04835         0.1495   \n",
       "536           0.11540         0.14630              0.06139         0.1926   \n",
       "91            0.10360         0.11220              0.07483         0.1717   \n",
       "297           0.05914         0.02685              0.03515         0.1619   \n",
       "\n",
       "     mean fractal dimension  ...  worst perimeter  worst area  \\\n",
       "385                 0.05416  ...           102.20       758.2   \n",
       "379                 0.07950  ...            91.76       508.1   \n",
       "194                 0.06672  ...           118.60       784.7   \n",
       "476                 0.06009  ...           112.10       828.5   \n",
       "157                 0.05268  ...           120.30      1032.0   \n",
       "363                 0.05593  ...           117.20      1009.0   \n",
       "536                 0.05982  ...           104.30       728.3   \n",
       "91                  0.06097  ...           107.50       830.9   \n",
       "297                 0.06287  ...            85.10       553.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "385           0.13120            0.15810           0.2675   \n",
       "379           0.21840            0.93790           0.8402   \n",
       "194           0.13160            0.46480           0.4589   \n",
       "476           0.11530            0.34290           0.2512   \n",
       "157           0.08774            0.17100           0.1882   \n",
       "363           0.13380            0.16790           0.1663   \n",
       "536           0.13800            0.27330           0.4234   \n",
       "91            0.12570            0.19970           0.2846   \n",
       "297           0.11370            0.07974           0.0612   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  \\\n",
       "385               0.13590          0.2477                  0.06836   \n",
       "379               0.25240          0.4154                  0.14030   \n",
       "194               0.17270          0.3000                  0.08701   \n",
       "476               0.13390          0.2534                  0.07858   \n",
       "157               0.08436          0.2527                  0.05972   \n",
       "363               0.09123          0.2394                  0.06469   \n",
       "536               0.13620          0.2698                  0.08351   \n",
       "91                0.14760          0.2556                  0.06828   \n",
       "297               0.07160          0.1978                  0.06915   \n",
       "\n",
       "     TargetColumn  PredictedCancer  \n",
       "385             0                1  \n",
       "379             0                1  \n",
       "194             0                1  \n",
       "476             1                0  \n",
       "157             1                0  \n",
       "363             1                0  \n",
       "536             0                1  \n",
       "91              0                1  \n",
       "297             0                1  \n",
       "\n",
       "[9 rows x 32 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TestingDataResults[TestingDataResults['TargetColumn'] != TestingDataResults['PredictedCancer']].head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference:\n",
    "\n",
    "* https://towardsdatascience.com/one-of-the-top-machine-learning-algorithms-for-supervised-learning-support-vector-machines-svms-fc45ac0667f4\n",
    "\n",
    "* https://www.youtube.com/watch?v=u3G1uJXIe5E\n",
    "\n",
    "* https://www.youtube.com/watch?v=H9yACitf-KM\n",
    "\n",
    "* https://www.youtube.com/watch?v=Js3GLb1xPhc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
